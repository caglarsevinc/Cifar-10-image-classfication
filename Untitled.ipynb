{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "proud-filing",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "considered-cowboy",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "resident-washington",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "hidden-luxury",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "suspected-jimmy",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "registered-shakespeare",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "written-rachel",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "silver-harassment",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "unusual-gospel",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "forced-lincoln",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "objective-circus",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import datasets, layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "closing-point",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test,y_test) = datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "isolated-traveler",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.reshape(-1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "noticed-perspective",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = y_test.reshape(-1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "owned-batman",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = X_train.astype('float32')\n",
    "x_test = X_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "latter-kazakhstan",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 8, 8, ..., 5, 1, 7], dtype=uint8)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "excess-breast",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 9, 9, ..., 9, 1, 1], dtype=uint8)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "removable-makeup",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\"airplane\",\"automobile\",\"bird\",\"cat\",\"deer\",\"dog\",\"frog\",\"horse\",\"ship\",\"truck\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "theoretical-tiger",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sample(X, y, index):\n",
    "    plt.figure(figsize = (15,2))\n",
    "    plt.imshow(X[index])\n",
    "    plt.xlabel(classes[y[index]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "registered-backup",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_sample(X_train, y_train, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "acoustic-reality",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = models.Sequential([\n",
    "    layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D((2, 2), padding='same'),\n",
    "    layers.Dropout(0.05),\n",
    "    \n",
    "\n",
    "    layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D((2, 2), padding='same'),\n",
    "    layers.Dropout(0.05),\n",
    "    \n",
    "\n",
    "    \n",
    "    layers.Conv2D(filters=128, kernel_size=(3, 3), activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Conv2D(filters=128, kernel_size=(3, 3), activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D((2, 2), padding='same'),\n",
    "    layers.Dropout(0.05),\n",
    "    \n",
    "    \n",
    "    layers.Flatten(),\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dropout(0.05),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "opponent-shield",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 30, 30, 32)        896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 30, 30, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 28, 28, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 28, 28, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 12, 12, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 12, 12, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 10, 10, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 10, 10, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 3, 3, 128)         73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 3, 3, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 1, 1, 128)         147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 1, 1, 128)         512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 359,978\n",
      "Trainable params: 359,082\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "expanded-pizza",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.compile(optimizer='Adamax',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "reserved-sheet",
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=200)\n",
    "mc = ModelCheckpoint('best_model.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "faced-transformation",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(width_shift_range=0.1, height_shift_range=0.1, horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "attended-transsexual",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "graduate-missile",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 25s 16ms/step - loss: 1.7209 - accuracy: 0.3723 - val_loss: 1.4568 - val_accuracy: 0.4944\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.49440, saving model to best_model.h5\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 24s 15ms/step - loss: 1.2091 - accuracy: 0.5665 - val_loss: 1.0659 - val_accuracy: 0.6203\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.49440 to 0.62030, saving model to best_model.h5\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 24s 15ms/step - loss: 1.0286 - accuracy: 0.6378 - val_loss: 0.9966 - val_accuracy: 0.6551\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.62030 to 0.65510, saving model to best_model.h5\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 24s 15ms/step - loss: 0.9031 - accuracy: 0.6866 - val_loss: 0.8790 - val_accuracy: 0.7009\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.65510 to 0.70090, saving model to best_model.h5\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 24s 16ms/step - loss: 0.8472 - accuracy: 0.7043 - val_loss: 0.7976 - val_accuracy: 0.7208\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.70090 to 0.72080, saving model to best_model.h5\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 24s 16ms/step - loss: 0.7875 - accuracy: 0.7221 - val_loss: 0.7046 - val_accuracy: 0.7586\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.72080 to 0.75860, saving model to best_model.h5\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 25s 16ms/step - loss: 0.7425 - accuracy: 0.7388 - val_loss: 0.6360 - val_accuracy: 0.7814\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.75860 to 0.78140, saving model to best_model.h5\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 24s 16ms/step - loss: 0.7189 - accuracy: 0.7487 - val_loss: 0.6671 - val_accuracy: 0.7713\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.78140\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 25s 16ms/step - loss: 0.6926 - accuracy: 0.7587 - val_loss: 0.6481 - val_accuracy: 0.7801\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.78140\n",
      "Epoch 10/10\n",
      " 921/1563 [================>.............] - ETA: 9s - loss: 0.6499 - accuracy: 0.7738"
     ]
    }
   ],
   "source": [
    "history = cnn.fit(datagen.flow(X_train, y_train), epochs=10,\n",
    "                 validation_data = (X_test, y_test), callbacks =[es, mc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "relative-nelson",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = cnn.evaluate(X_test, y_test, verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effective-compilation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score trained model.\n",
    "scores = cnn.evaluate(X_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "executive-cornell",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0.1, 1])\n",
    "plt.legend(loc='lower right')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nasty-convertible",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotmodelhistory(history): \n",
    "    fig, axs = plt.subplots(1,2,figsize=(15,5)) \n",
    "    # summarize history for accuracy\n",
    "    axs[0].plot(history.history['accuracy']) \n",
    "    axs[0].plot(history.history['val_accuracy']) \n",
    "    axs[0].set_title('Model Accuracy')\n",
    "    axs[0].set_ylabel('Accuracy') \n",
    "    axs[0].set_xlabel('Epoch')\n",
    "    axs[0].legend(['train', 'validate'], loc='upper left')\n",
    "    # summarize history for loss\n",
    "    axs[1].plot(history.history['loss']) \n",
    "    axs[1].plot(history.history['val_loss']) \n",
    "    axs[1].set_title('Model Loss')\n",
    "    axs[1].set_ylabel('Loss') \n",
    "    axs[1].set_xlabel('Epoch')\n",
    "    axs[1].legend(['train', 'validate'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "\n",
    "plotmodelhistory(history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
